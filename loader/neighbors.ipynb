{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: UTF-8\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from posixpath import join\n",
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# using labse\n",
    "# from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import *\n",
    "\n",
    "from script.preprocess.deal_raw_dataset import MyRawdataset\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码组织结构\n",
    "DBP15KRawNeighbors():  \n",
    "\n",
    "load读取的是labse编码的entity的embedding    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:/ForkWork/SelfKG/data/DBP15K/zh_en/LaBSE_emb_1.pkl', 'rb') as f:\n",
    "    id_entity = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the length of id_entity is {}, type is {}\".format(len(id_entity),type(id_entity)))\n",
    "print(len(id_entity[0][0]))\n",
    "x = np.array(id_entity[0])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id_neighbors_loader读取的是src/tgt的triple(ids)。这里判断tail是head的邻居.\n",
    "1. head_str其实是row[head]的embedding  \n",
    "2. id_neighbors_dict保存的是key:head; value:head的所有tail的embedding\n",
    "和 key:tail; value:tail的所有head的embedding。保存了所有实体id对应的邻居embedding，第0个代表的是自己。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'E:/ForkWork/SelfKG/data/DBP15K/zh_en/triples_1'\n",
    "data = pd.read_csv(filepath, header=None, sep='\\t')\n",
    "data.columns = ['head', 'relation', 'tail']\n",
    "id_neighbors_dict = {}\n",
    "for index, row in data.iterrows():\n",
    "    head_str = id_entity[int(row['head'])][0]\n",
    "    tail_str = id_entity[int(row['tail'])][0]\n",
    "\n",
    "    if not int(row['head']) in id_neighbors_dict.keys():\n",
    "        id_neighbors_dict[int(row['head'])] = [head_str]\n",
    "    if not tail_str in id_neighbors_dict[int(row['head'])]:\n",
    "        id_neighbors_dict[int(row['head'])].append(tail_str)\n",
    "    \n",
    "    if not int(row['tail']) in id_neighbors_dict.keys():\n",
    "        id_neighbors_dict[int(row['tail'])] = [tail_str]\n",
    "    if not head_str in id_neighbors_dict[int(row['tail'])]:\n",
    "        id_neighbors_dict[int(row['tail'])].append(head_str)\n",
    "# len(id_neighbors_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_adj是创建邻接矩阵，对角，第一行，第一列。每个节点能到自己，第0个表示自己，能到自己的所有邻居，所有邻居能到第0个节点。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(valid_len):\n",
    "    adj = torch.zeros(NEIGHBOR_SIZE, NEIGHBOR_SIZE).bool()\n",
    "    for i in range(0, valid_len):\n",
    "        adj[i, i] = 1\n",
    "        adj[0, i] = 1\n",
    "        adj[i, 0] = 1\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_center_adj是造出来：\n",
    "1. id_adj_tensor_dict：dict，是当前实体的邻接矩阵。20*20  \n",
    "2. id_neighbors_dict:dict, padding扩展到20个neighbors。v是个二维矩阵. 20*768\n",
    "比20大的截断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_adj_tensor_dict = {}\n",
    "for k, v in id_neighbors_dict.items():\n",
    "    if len(v) < NEIGHBOR_SIZE:\n",
    "        id_adj_tensor_dict[k] = get_adj(len(v))\n",
    "        id_neighbors_dict[k] = v + [[0]*LaBSE_DIM] * (NEIGHBOR_SIZE - len(v))\n",
    "    else:\n",
    "        id_adj_tensor_dict[k] = get_adj(NEIGHBOR_SIZE)\n",
    "        id_neighbors_dict[k] = v[:NEIGHBOR_SIZE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(id_adj_tensor_dict))\n",
    "print(len(id_neighbors_dict))\n",
    "#entity一共19388个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in id_adj_tensor_dict:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_adj = None\n",
    "x_train = []\n",
    "y_train = []\n",
    "for k in id_neighbors_dict:\n",
    "    if x_train_adj==None:\n",
    "        x_train_adj = id_adj_tensor_dict[k].unsqueeze(0)\n",
    "    else:\n",
    "        x_train_adj = torch.cat((x_train_adj,id_adj_tensor_dict[k].unsqueeze(0)),dim=0)\n",
    "    x_train.append(id_neighbors_dict[k])\n",
    "    y_train.append([k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_adj.shape\n",
    "# 7w+的triple 19388个entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.Tensor(x_train)\n",
    "x_train = torch.cat((x_train,x_train_adj),dim=2)\n",
    "y_train = torch.Tensor(y_train).long()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('selfkg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c10886b160ef380b9a9899d7cd46ed4ff0f65536336b80e7f9abe4df9e948776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
